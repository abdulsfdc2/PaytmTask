{"cells":[{"cell_type":"code","source":["ratings_schema = \"`UserID` INT, `MovieID` INT, `Rating` INT, `Timestamp` bigint\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"069e15cd-9be9-4e22-9461-812fcf755d9e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# File location and type\nratings_file_location = \"dbfs:/FileStore/tables/ratings.dat\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c21d3e08-1c75-4aae-ab39-2919c08db582"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["Ratings_DF=spark.read.format(\"csv\").option(\"delimiter\", \"::\").schema(ratings_schema).load(ratings_file_location)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"722b040d-41b9-436f-bfd4-2ce569db5574"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nmovies_schema = StructType([ \n    StructField(\"MovieID\",IntegerType(),True), \n    StructField(\"Title\",StringType(),True), \n    StructField(\"Genres\",StringType(), True)])\nmovies_file_location = \"dbfs:/FileStore/tables/movies.dat\"\nMovies_DF=spark.read.format(\"csv\").option(\"delimiter\", \"::\").schema(movies_schema).load(movies_file_location)\nFinal_Movies_DF=Movies_DF.withColumn(\"Genres\",explode(split(\"Genres\",\"[|]\")))\nFinal_Movies_DF.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1029188-1fa1-4950-8895-95a2b8eb2a39"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+--------------------+---------+\n|MovieID|               Title|   Genres|\n+-------+--------------------+---------+\n|      1|    Toy Story (1995)|Adventure|\n|      1|    Toy Story (1995)|Animation|\n|      1|    Toy Story (1995)| Children|\n|      1|    Toy Story (1995)|   Comedy|\n|      1|    Toy Story (1995)|  Fantasy|\n|      2|      Jumanji (1995)|Adventure|\n|      2|      Jumanji (1995)| Children|\n|      2|      Jumanji (1995)|  Fantasy|\n|      3|Grumpier Old Men ...|   Comedy|\n|      3|Grumpier Old Men ...|  Romance|\n|      4|Waiting to Exhale...|   Comedy|\n|      4|Waiting to Exhale...|    Drama|\n|      4|Waiting to Exhale...|  Romance|\n|      5|Father of the Bri...|   Comedy|\n|      6|         Heat (1995)|   Action|\n|      6|         Heat (1995)|    Crime|\n|      6|         Heat (1995)| Thriller|\n|      7|      Sabrina (1995)|   Comedy|\n|      7|      Sabrina (1995)|  Romance|\n|      8| Tom and Huck (1995)|Adventure|\n+-------+--------------------+---------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+--------------------+---------+\nMovieID|               Title|   Genres|\n+-------+--------------------+---------+\n      1|    Toy Story (1995)|Adventure|\n      1|    Toy Story (1995)|Animation|\n      1|    Toy Story (1995)| Children|\n      1|    Toy Story (1995)|   Comedy|\n      1|    Toy Story (1995)|  Fantasy|\n      2|      Jumanji (1995)|Adventure|\n      2|      Jumanji (1995)| Children|\n      2|      Jumanji (1995)|  Fantasy|\n      3|Grumpier Old Men ...|   Comedy|\n      3|Grumpier Old Men ...|  Romance|\n      4|Waiting to Exhale...|   Comedy|\n      4|Waiting to Exhale...|    Drama|\n      4|Waiting to Exhale...|  Romance|\n      5|Father of the Bri...|   Comedy|\n      6|         Heat (1995)|   Action|\n      6|         Heat (1995)|    Crime|\n      6|         Heat (1995)| Thriller|\n      7|      Sabrina (1995)|   Comedy|\n      7|      Sabrina (1995)|  Romance|\n      8| Tom and Huck (1995)|Adventure|\n+-------+--------------------+---------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# What are the titles of top 5 most popular movies i.e. have the most ranking in the whole dataset?\njoinDF=Final_Movies_DF.join(Ratings_DF,Final_Movies_DF.MovieID==Ratings_DF.MovieID).drop(Ratings_DF.MovieID)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a4ea508-df62-439d-a878-4d7123b21016"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["joinDF.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7af476c8-8f8f-4e69-8d39-aa4bcd57fbfb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+--------------------+---------+------+------+---------+\n|MovieID|               Title|   Genres|UserID|Rating|Timestamp|\n+-------+--------------------+---------+------+------+---------+\n|    122|    Boomerang (1992)|  Romance|     1|     5|838985046|\n|    122|    Boomerang (1992)|   Comedy|     1|     5|838985046|\n|    185|     Net, The (1995)| Thriller|     1|     5|838983525|\n|    185|     Net, The (1995)|    Crime|     1|     5|838983525|\n|    185|     Net, The (1995)|   Action|     1|     5|838983525|\n|    231|Dumb &amp; Dumber (1994)|   Comedy|     1|     5|838983392|\n|    292|     Outbreak (1995)| Thriller|     1|     5|838983421|\n|    292|     Outbreak (1995)|   Sci-Fi|     1|     5|838983421|\n|    292|     Outbreak (1995)|    Drama|     1|     5|838983421|\n|    292|     Outbreak (1995)|   Action|     1|     5|838983421|\n|    316|     Stargate (1994)|   Sci-Fi|     1|     5|838983392|\n|    316|     Stargate (1994)|Adventure|     1|     5|838983392|\n|    316|     Stargate (1994)|   Action|     1|     5|838983392|\n|    329|Star Trek: Genera...|   Sci-Fi|     1|     5|838983392|\n|    329|Star Trek: Genera...|    Drama|     1|     5|838983392|\n|    329|Star Trek: Genera...|Adventure|     1|     5|838983392|\n|    329|Star Trek: Genera...|   Action|     1|     5|838983392|\n|    355|Flintstones, The ...|  Fantasy|     1|     5|838984474|\n|    355|Flintstones, The ...|   Comedy|     1|     5|838984474|\n|    355|Flintstones, The ...| Children|     1|     5|838984474|\n+-------+--------------------+---------+------+------+---------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+--------------------+---------+------+------+---------+\nMovieID|               Title|   Genres|UserID|Rating|Timestamp|\n+-------+--------------------+---------+------+------+---------+\n    122|    Boomerang (1992)|  Romance|     1|     5|838985046|\n    122|    Boomerang (1992)|   Comedy|     1|     5|838985046|\n    185|     Net, The (1995)| Thriller|     1|     5|838983525|\n    185|     Net, The (1995)|    Crime|     1|     5|838983525|\n    185|     Net, The (1995)|   Action|     1|     5|838983525|\n    231|Dumb &amp; Dumber (1994)|   Comedy|     1|     5|838983392|\n    292|     Outbreak (1995)| Thriller|     1|     5|838983421|\n    292|     Outbreak (1995)|   Sci-Fi|     1|     5|838983421|\n    292|     Outbreak (1995)|    Drama|     1|     5|838983421|\n    292|     Outbreak (1995)|   Action|     1|     5|838983421|\n    316|     Stargate (1994)|   Sci-Fi|     1|     5|838983392|\n    316|     Stargate (1994)|Adventure|     1|     5|838983392|\n    316|     Stargate (1994)|   Action|     1|     5|838983392|\n    329|Star Trek: Genera...|   Sci-Fi|     1|     5|838983392|\n    329|Star Trek: Genera...|    Drama|     1|     5|838983392|\n    329|Star Trek: Genera...|Adventure|     1|     5|838983392|\n    329|Star Trek: Genera...|   Action|     1|     5|838983392|\n    355|Flintstones, The ...|  Fantasy|     1|     5|838984474|\n    355|Flintstones, The ...|   Comedy|     1|     5|838984474|\n    355|Flintstones, The ...| Children|     1|     5|838984474|\n+-------+--------------------+---------+------+------+---------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#What are the titles of top 5 most popular movies i.e. have the most ranking in the whole dataset?\nfrom pyspark.sql.functions import desc\njoinDF.groupBy(\"Title\").agg(sum(\"Rating\").alias(\"popularity\")).filter(col(\"popularity\").isNotNull()).sort(desc(\"popularity\")).show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8249b948-aa5f-4f78-8ebb-025405de28c6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+----------+\n|               Title|popularity|\n+--------------------+----------+\n|  Captain Ron (1992)|   2001284|\n| Forrest Gump (1994)|    479352|\n|    Toy Story (1995)|    448135|\n|Jurassic Park (1993)|    414880|\n|    True Lies (1994)|    393775|\n+--------------------+----------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+----------+\n               Title|popularity|\n+--------------------+----------+\n  Captain Ron (1992)|   2001284|\n Forrest Gump (1994)|    479352|\n    Toy Story (1995)|    448135|\nJurassic Park (1993)|    414880|\n    True Lies (1994)|    393775|\n+--------------------+----------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#What are the top 5 ranked movie genres on average in the whole dataset?\njoinDF.groupBy(\"Genres\").agg(avg(\"Rating\").alias(\"popularity_genres\")).filter(col(\"popularity_genres\").isNotNull()).sort(desc(\"popularity_genres\")).show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3176d7c6-d26b-44ad-92b9-c66d34ca48f0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------+------------------+\n|     Genres| popularity_genres|\n+-----------+------------------+\n|  Adventure| 4.140160488236416|\n|  Film-Noir| 4.058143276237343|\n|Documentary|3.8515663616324893|\n|        War|3.8347471983177885|\n|       IMAX|             3.825|\n+-----------+------------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+------------------+\n     Genres| popularity_genres|\n+-----------+------------------+\n  Adventure| 4.140160488236416|\n  Film-Noir| 4.058143276237343|\nDocumentary|3.8515663616324893|\n        War|3.8347471983177885|\n       IMAX|             3.825|\n+-----------+------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#How many movies have been ranked the most consecutive days?\nfrom pyspark.sql.functions import from_utc_timestamp\njoinDF= joinDF.withColumn(\"Timestamp\",(col(\"Timestamp\") / 1e6).cast(\"Timestamp\"))\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15a0e509-2e47-42b2-b915-08efcad08249"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["joinDF.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7006945c-af27-4b06-b008-91d00cb3a005"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+--------------------+---------+------+------+--------------------+\n|MovieID|               Title|   Genres|UserID|Rating|           Timestamp|\n+-------+--------------------+---------+------+------+--------------------+\n|    122|    Boomerang (1992)|  Romance|     1|     5|1970-01-01 00:13:...|\n|    122|    Boomerang (1992)|   Comedy|     1|     5|1970-01-01 00:13:...|\n|    185|     Net, The (1995)| Thriller|     1|     5|1970-01-01 00:13:...|\n|    185|     Net, The (1995)|    Crime|     1|     5|1970-01-01 00:13:...|\n|    185|     Net, The (1995)|   Action|     1|     5|1970-01-01 00:13:...|\n|    231|Dumb &amp; Dumber (1994)|   Comedy|     1|     5|1970-01-01 00:13:...|\n|    292|     Outbreak (1995)| Thriller|     1|     5|1970-01-01 00:13:...|\n|    292|     Outbreak (1995)|   Sci-Fi|     1|     5|1970-01-01 00:13:...|\n|    292|     Outbreak (1995)|    Drama|     1|     5|1970-01-01 00:13:...|\n|    292|     Outbreak (1995)|   Action|     1|     5|1970-01-01 00:13:...|\n|    316|     Stargate (1994)|   Sci-Fi|     1|     5|1970-01-01 00:13:...|\n|    316|     Stargate (1994)|Adventure|     1|     5|1970-01-01 00:13:...|\n|    316|     Stargate (1994)|   Action|     1|     5|1970-01-01 00:13:...|\n|    329|Star Trek: Genera...|   Sci-Fi|     1|     5|1970-01-01 00:13:...|\n|    329|Star Trek: Genera...|    Drama|     1|     5|1970-01-01 00:13:...|\n|    329|Star Trek: Genera...|Adventure|     1|     5|1970-01-01 00:13:...|\n|    329|Star Trek: Genera...|   Action|     1|     5|1970-01-01 00:13:...|\n|    355|Flintstones, The ...|  Fantasy|     1|     5|1970-01-01 00:13:...|\n|    355|Flintstones, The ...|   Comedy|     1|     5|1970-01-01 00:13:...|\n|    355|Flintstones, The ...| Children|     1|     5|1970-01-01 00:13:...|\n+-------+--------------------+---------+------+------+--------------------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+--------------------+---------+------+------+--------------------+\nMovieID|               Title|   Genres|UserID|Rating|           Timestamp|\n+-------+--------------------+---------+------+------+--------------------+\n    122|    Boomerang (1992)|  Romance|     1|     5|1970-01-01 00:13:...|\n    122|    Boomerang (1992)|   Comedy|     1|     5|1970-01-01 00:13:...|\n    185|     Net, The (1995)| Thriller|     1|     5|1970-01-01 00:13:...|\n    185|     Net, The (1995)|    Crime|     1|     5|1970-01-01 00:13:...|\n    185|     Net, The (1995)|   Action|     1|     5|1970-01-01 00:13:...|\n    231|Dumb &amp; Dumber (1994)|   Comedy|     1|     5|1970-01-01 00:13:...|\n    292|     Outbreak (1995)| Thriller|     1|     5|1970-01-01 00:13:...|\n    292|     Outbreak (1995)|   Sci-Fi|     1|     5|1970-01-01 00:13:...|\n    292|     Outbreak (1995)|    Drama|     1|     5|1970-01-01 00:13:...|\n    292|     Outbreak (1995)|   Action|     1|     5|1970-01-01 00:13:...|\n    316|     Stargate (1994)|   Sci-Fi|     1|     5|1970-01-01 00:13:...|\n    316|     Stargate (1994)|Adventure|     1|     5|1970-01-01 00:13:...|\n    316|     Stargate (1994)|   Action|     1|     5|1970-01-01 00:13:...|\n    329|Star Trek: Genera...|   Sci-Fi|     1|     5|1970-01-01 00:13:...|\n    329|Star Trek: Genera...|    Drama|     1|     5|1970-01-01 00:13:...|\n    329|Star Trek: Genera...|Adventure|     1|     5|1970-01-01 00:13:...|\n    329|Star Trek: Genera...|   Action|     1|     5|1970-01-01 00:13:...|\n    355|Flintstones, The ...|  Fantasy|     1|     5|1970-01-01 00:13:...|\n    355|Flintstones, The ...|   Comedy|     1|     5|1970-01-01 00:13:...|\n    355|Flintstones, The ...| Children|     1|     5|1970-01-01 00:13:...|\n+-------+--------------------+---------+------+------+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Count the total number of ratings in the dataset\nnumerator = Ratings_DF.select(\"Rating\").count()\n\n# Count the number of distinct userIds and distinct movieIds\nnum_users = Ratings_DF.select(\"UserID\").distinct().count()\nnum_movies = Ratings_DF.select(\"MovieID\").distinct().count()\n\n# Set the denominator equal to the number of users multiplied by the number of movies\ndenominator = num_users * num_movies\n\n# Divide the numerator by the denominator\nsparsity = (1.0 - (numerator *1.0)/denominator)*100\nprint(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07302b96-71b8-41b6-8766-d94517326947"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">The ratings dataframe is  98.66% empty.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The ratings dataframe is  98.66% empty.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[" #Group data by userId, count ratings\nuserId_ratings = Ratings_DF.groupBy(\"UserID\").count().orderBy('count', ascending=False)\nuserId_ratings.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7cb97359-bae2-4abb-8786-13622f15ecda"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+-----+\n|UserID|count|\n+------+-----+\n| 59269| 7359|\n| 67385| 7047|\n| 14463| 5169|\n| 68259| 4483|\n| 27468| 4449|\n| 19635| 4165|\n|  3817| 4165|\n| 63134| 3755|\n| 58357| 3697|\n| 27584| 3479|\n|  6757| 3414|\n| 56707| 3225|\n| 19379| 3202|\n|  7795| 3187|\n|  8811| 3164|\n| 30723| 3027|\n| 30687| 2909|\n| 31327| 2886|\n| 30500| 2827|\n| 47046| 2812|\n+------+-----+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-----+\nUserID|count|\n+------+-----+\n 59269| 7359|\n 67385| 7047|\n 14463| 5169|\n 68259| 4483|\n 27468| 4449|\n 19635| 4165|\n  3817| 4165|\n 63134| 3755|\n 58357| 3697|\n 27584| 3479|\n  6757| 3414|\n 56707| 3225|\n 19379| 3202|\n  7795| 3187|\n  8811| 3164|\n 30723| 3027|\n 30687| 2909|\n 31327| 2886|\n 30500| 2827|\n 47046| 2812|\n+------+-----+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Group data by userId, count ratings\nmovieId_ratings = Ratings_DF.groupBy(\"MovieID\").count().orderBy('count', ascending=False)\nmovieId_ratings.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad2bc70b-e56e-4b42-8b88-de6da54cc53d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+-----+\n|MovieId|count|\n+-------+-----+\n|    296|34864|\n|    356|34457|\n|    593|33668|\n|    480|32631|\n|    318|31126|\n|    110|29154|\n|    457|28951|\n|    589|28948|\n|    260|28566|\n|    150|27035|\n|    592|26996|\n|      1|26449|\n|    780|26042|\n|    590|25912|\n|    527|25777|\n|    380|25381|\n|   1210|25098|\n|     32|24397|\n|     50|24037|\n|    608|23794|\n+-------+-----+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-----+\nMovieId|count|\n+-------+-----+\n    296|34864|\n    356|34457|\n    593|33668|\n    480|32631|\n    318|31126|\n    110|29154|\n    457|28951|\n    589|28948|\n    260|28566|\n    150|27035|\n    592|26996|\n      1|26449|\n    780|26042|\n    590|25912|\n    527|25777|\n    380|25381|\n   1210|25098|\n     32|24397|\n     50|24037|\n    608|23794|\n+-------+-----+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Import the required functions\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b99f070b-55d8-49a4-9e1a-65748d37638e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":[" #Create test and train set\n(train, test) = Ratings_DF.randomSplit([0.8, 0.2], seed = 1234)\n\n# Create ALS model\nals = ALS(userCol=\"UserID\", itemCol=\"MovieID\", ratingCol=\"Rating\", nonnegative = True, implicitPrefs = False, coldStartStrategy=\"drop\")\n\n# Confirm that a model called \"als\" was created\ntype(als)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"887068c8-2e27-4e15-80ea-2f9ec5565449"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[176]: pyspark.ml.recommendation.ALS</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[176]: pyspark.ml.recommendation.ALS</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Import the required functions\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56f890d7-e3ee-4010-8251-a849c7c7c13a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create test and train set\n(train, test) = Ratings_DF.randomSplit([0.8, 0.2], seed = 1234)\n\n# Create ALS model\nals = ALS(userCol=\"UserID\", itemCol=\"MovieID\", ratingCol=\"Rating\", nonnegative = True, implicitPrefs = False, coldStartStrategy=\"drop\")\n\n# Confirm that a model called \"als\" was created\ntype(als)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74b5829f-9d2b-49a1-9fb5-31ffa8375845"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[195]: pyspark.ml.recommendation.ALS</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[195]: pyspark.ml.recommendation.ALS</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Import the requisite items\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Add hyperparameters and their respective values to param_grid\nparam_grid = ParamGridBuilder() \\\n            .addGrid(als.rank, [10, 50, 100, 150]) \\\n            .addGrid(als.regParam, [.01, .05, .1, .15]) \\\n            .build()\n            #             .addGrid(als.maxIter, [5, 50, 100, 200]) \\\n\n           \n# Define evaluator as RMSE and print length of evaluator\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\") \nprint (\"Num models to be tested: \", len(param_grid))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88fe3666-390e-4b47-9a8a-95a007c808fc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4417672089706678&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\">#Training the Model</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>alsModel <span class=\"ansi-blue-fg\">=</span> als<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>train<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">#Generating Predictions</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> prediction <span class=\"ansi-blue-fg\">=</span> alsModel<span class=\"ansi-blue-fg\">.</span>transform<span class=\"ansi-blue-fg\">(</span>test<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> prediction<span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, dataset, params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    159</span>                 <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>copy<span class=\"ansi-blue-fg\">(</span>params<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>_fit<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    160</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 161</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_fit<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    162</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    163</span>             raise ValueError(&#34;Params must be either a param map or a list/tuple of param maps, &#34;\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansi-cyan-fg\">_fit</span><span class=\"ansi-blue-fg\">(self, dataset)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    333</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    334</span>     <span class=\"ansi-green-fg\">def</span> _fit<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> dataset<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 335</span><span class=\"ansi-red-fg\">         </span>java_model <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_fit_java<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    336</span>         model <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_create_model<span class=\"ansi-blue-fg\">(</span>java_model<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    337</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_copyValues<span class=\"ansi-blue-fg\">(</span>model<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansi-cyan-fg\">_fit_java</span><span class=\"ansi-blue-fg\">(self, dataset)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">    331</span>         self<span class=\"ansi-blue-fg\">.</span>_transfer_params_to_java<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 332</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_java_obj<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    333</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    334</span>     <span class=\"ansi-green-fg\">def</span> _fit<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> dataset<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    108</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    109</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 110</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    111</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    112</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    324</span>             value <span class=\"ansi-blue-fg\">=</span> OUTPUT_CONVERTER<span class=\"ansi-blue-fg\">[</span>type<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span>answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">if</span> answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> REFERENCE_TYPE<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 326</span><span class=\"ansi-red-fg\">                 raise Py4JJavaError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o19565.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 240.0 failed 1 times, most recent failure: Lost task 0.0 in stage 240.0 (TID 461) (ip-10-172-228-150.us-west-2.compute.internal executor driver): org.apache.spark.SparkException: Failed to execute user defined function(ALSModelParams$$Lambda$6453/1834507155: (int) =&gt; int)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:754)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$SliceIterator.hasNext(Iterator.scala:266)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1429)\n\tat org.apache.spark.rdd.RDD.$anonfun$take$2(RDD.scala:1461)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$2(SparkContext.scala:2492)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:150)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:119)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$10(Executor.scala:732)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1643)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:735)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: ALS only supports values in Integer range for columns UserID and MovieID. Value null was not numeric.\n\tat org.apache.spark.ml.recommendation.ALSModelParams.$anonfun$checkedCast$1(ALS.scala:105)\n\tat org.apache.spark.ml.recommendation.ALSModelParams.$anonfun$checkedCast$1$adapted(ALS.scala:90)\n\t... 34 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2711)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2658)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2652)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2652)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1255)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1255)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1255)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2919)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2848)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1029)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2452)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2435)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2473)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2492)\n\tat org.apache.spark.rdd.RDD.$anonfun$take$1(RDD.scala:1461)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:419)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1434)\n\tat org.apache.spark.rdd.RDD.$anonfun$isEmpty$1(RDD.scala:1580)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:419)\n\tat org.apache.spark.rdd.RDD.isEmpty(RDD.scala:1580)\n\tat org.apache.spark.ml.recommendation.ALS$.train(ALS.scala:948)\n\tat org.apache.spark.ml.recommendation.ALS.$anonfun$fit$1(ALS.scala:710)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:284)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:284)\n\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:692)\n\tat sun.reflect.GeneratedMethodAccessor627.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(ALSModelParams$$Lambda$6453/1834507155: (int) =&gt; int)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:754)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$SliceIterator.hasNext(Iterator.scala:266)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1429)\n\tat org.apache.spark.rdd.RDD.$anonfun$take$2(RDD.scala:1461)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$2(SparkContext.scala:2492)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:150)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:119)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$10(Executor.scala:732)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1643)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:735)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.lang.IllegalArgumentException: ALS only supports values in Integer range for columns UserID and MovieID. Value null was not numeric.\n\tat org.apache.spark.ml.recommendation.ALSModelParams.$anonfun$checkedCast$1(ALS.scala:105)\n\tat org.apache.spark.ml.recommendation.ALSModelParams.$anonfun$checkedCast$1$adapted(ALS.scala:90)\n\t... 34 more\n</div>","errorSummary":"org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 240.0 failed 1 times, most recent failure: Lost task 0.0 in stage 240.0 (TID 461) (ip-10-172-228-150.us-west-2.compute.internal executor driver): org.apache.spark.SparkException: Failed to execute user defined function(ALSModelParams$$Lambda$6453/1834507155: (int) =&gt; int)","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4417672089706678&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\">#Training the Model</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>alsModel <span class=\"ansi-blue-fg\">=</span> als<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>train<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">#Generating Predictions</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> prediction <span class=\"ansi-blue-fg\">=</span> alsModel<span class=\"ansi-blue-fg\">.</span>transform<span class=\"ansi-blue-fg\">(</span>test<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> prediction<span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, dataset, params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    159</span>                 <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>copy<span class=\"ansi-blue-fg\">(</span>params<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>_fit<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    160</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 161</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_fit<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    162</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    163</span>             raise ValueError(&#34;Params must be either a param map or a list/tuple of param maps, &#34;\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansi-cyan-fg\">_fit</span><span class=\"ansi-blue-fg\">(self, dataset)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    333</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    334</span>     <span class=\"ansi-green-fg\">def</span> _fit<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> dataset<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 335</span><span class=\"ansi-red-fg\">         </span>java_model <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_fit_java<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    336</span>         model <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_create_model<span class=\"ansi-blue-fg\">(</span>java_model<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    337</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_copyValues<span class=\"ansi-blue-fg\">(</span>model<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansi-cyan-fg\">_fit_java</span><span class=\"ansi-blue-fg\">(self, dataset)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">    331</span>         self<span class=\"ansi-blue-fg\">.</span>_transfer_params_to_java<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 332</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_java_obj<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    333</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    334</span>     <span class=\"ansi-green-fg\">def</span> _fit<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> dataset<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    108</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    109</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 110</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    111</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    112</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    324</span>             value <span class=\"ansi-blue-fg\">=</span> OUTPUT_CONVERTER<span class=\"ansi-blue-fg\">[</span>type<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span>answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">if</span> answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> REFERENCE_TYPE<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 326</span><span class=\"ansi-red-fg\">                 raise Py4JJavaError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o19565.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 240.0 failed 1 times, most recent failure: Lost task 0.0 in stage 240.0 (TID 461) (ip-10-172-228-150.us-west-2.compute.internal executor driver): org.apache.spark.SparkException: Failed to execute user defined function(ALSModelParams$$Lambda$6453/1834507155: (int) =&gt; int)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:754)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$SliceIterator.hasNext(Iterator.scala:266)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1429)\n\tat org.apache.spark.rdd.RDD.$anonfun$take$2(RDD.scala:1461)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$2(SparkContext.scala:2492)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:150)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:119)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$10(Executor.scala:732)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1643)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:735)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: ALS only supports values in Integer range for columns UserID and MovieID. Value null was not numeric.\n\tat org.apache.spark.ml.recommendation.ALSModelParams.$anonfun$checkedCast$1(ALS.scala:105)\n\tat org.apache.spark.ml.recommendation.ALSModelParams.$anonfun$checkedCast$1$adapted(ALS.scala:90)\n\t... 34 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2711)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2658)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2652)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2652)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1255)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1255)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1255)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2919)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2848)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1029)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2452)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2435)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2473)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2492)\n\tat org.apache.spark.rdd.RDD.$anonfun$take$1(RDD.scala:1461)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:419)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1434)\n\tat org.apache.spark.rdd.RDD.$anonfun$isEmpty$1(RDD.scala:1580)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:419)\n\tat org.apache.spark.rdd.RDD.isEmpty(RDD.scala:1580)\n\tat org.apache.spark.ml.recommendation.ALS$.train(ALS.scala:948)\n\tat org.apache.spark.ml.recommendation.ALS.$anonfun$fit$1(ALS.scala:710)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:284)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:284)\n\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:692)\n\tat sun.reflect.GeneratedMethodAccessor627.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(ALSModelParams$$Lambda$6453/1834507155: (int) =&gt; int)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:754)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$SliceIterator.hasNext(Iterator.scala:266)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1429)\n\tat org.apache.spark.rdd.RDD.$anonfun$take$2(RDD.scala:1461)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$2(SparkContext.scala:2492)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:150)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:119)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$10(Executor.scala:732)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1643)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:735)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.lang.IllegalArgumentException: ALS only supports values in Integer range for columns UserID and MovieID. Value null was not numeric.\n\tat org.apache.spark.ml.recommendation.ALSModelParams.$anonfun$checkedCast$1(ALS.scala:105)\n\tat org.apache.spark.ml.recommendation.ALSModelParams.$anonfun$checkedCast$1$adapted(ALS.scala:90)\n\t... 34 more\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Build cross validation using CrossValidator\ncv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n\n# Confirm cv was built\nprint(cv)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87d13012-5889-4fda-bf2d-a06fdbbb1f54"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Fit cross validator to the 'train' dataset\nmodel = cv.fit(train)\n\n#Extract best model from the cv model above\nbest_model = model.bestModel"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63771b38-2052-4e39-9cc1-bc488c1e3328"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Print best_model\nprint(type(best_model))\n\n# Complete the code below to extract the ALS model parameters\nprint(\"**Best Model**\")\n\n# # Print \"Rank\"\nprint(\"  Rank:\", best_model._java_obj.parent().getRank())\n\n# Print \"MaxIter\"\nprint(\"  MaxIter:\", best_model._java_obj.parent().getMaxIter())\n\n# Print \"RegParam\"\nprint(\"  RegParam:\", best_model._java_obj.parent().getRegParam())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"34e5cc47-ef6e-4011-8657-81c04664b18c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# View the predictions\ntest_predictions = best_model.transform(test)\nRMSE = evaluator.evaluate(test_predictions)\nprint(RMSE)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e06405b-9ce8-4b66-a2f1-3d7d343153ce"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Generate n Recommendations for all users\nnrecommendations = best_model.recommendForAllUsers(5)\nnrecommendations.limit(10).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03ec4a83-f3c8-4209-a09e-bef5e1ba9625"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["nrecommendations = nrecommendations\\\n    .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n    .select('userId', col(\"rec_exp.movieId\"), col(\"rec_exp.rating\"))\n\nnrecommendations.limit(10).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f17c100-27fa-4f26-9c86-d53b7ff48eca"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ml","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1928102085039201}},"nbformat":4,"nbformat_minor":0}
